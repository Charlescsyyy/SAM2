model:
  _target_: sam2.modeling.sam2_base.SAM2Base
  image_encoder:
    _target_: sam2.modeling.backbones.image_encoder.ImageEncoder
    trunk:
      _target_: sam2.modeling.backbones.vit_multiscale.ViTTrunkMultiScale
      pretrained: /path/to/dinov3_vit_l16_or_224m_dir   # HF id or local dir
      encoder_type: dino
      out_dims: null            # null => [D,D,D,D]
      upsample_mode: bilinear   # bilinear|deconv
      refine_highres: true
      freeze_vit: false
      force_dtype: null         # null|bf16|fp16|fp32
      verbose: false
    neck:
      _target_: sam2.modeling.backbones.image_encoder.FpnNeck
      position_encoding:
        _target_: sam2.modeling.position_encoding.PositionEmbeddingSine
        num_pos_feats: 256
        normalize: true
        scale: null
        temperature: 10000
      d_model: 256
      # will be overridden at runtime if out_dims provided
      backbone_channel_list: [1024, 1024, 1024, 1024]
      fpn_top_down_levels: [0, 1]
      fpn_interp_model: nearest

  memory_attention: ${model_from:sam2_hiera_l.yaml:model.memory_attention}
  memory_encoder: ${model_from:sam2_hiera_l.yaml:model.memory_encoder}
  num_maskmem: 7
  image_size: 1024
  sigmoid_scale_for_mem_enc: 20.0
  sigmoid_bias_for_mem_enc: -10.0
  use_mask_input_as_output_without_sam: true
  directly_add_no_mem_embed: true
  use_high_res_features_in_sam: true
  multimask_output_in_sam: true
  iou_prediction_use_sigmoid: True
  use_obj_ptrs_in_encoder: true
  add_tpos_enc_to_obj_ptrs: false
  only_obj_ptrs_in_the_past_for_eval: true
  pred_obj_scores: true
  pred_obj_scores_mlp: true
  fixed_no_obj_ptr: true
  multimask_output_for_tracking: true
  use_multimask_token_for_obj_ptr: true
  multimask_min_pt_num: 0
  multimask_max_pt_num: 1
  use_mlp_for_obj_ptr_proj: true
  compile_image_encoder: False
